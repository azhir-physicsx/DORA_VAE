{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1b1127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azhir/Dora/pytorch_lightning/craftsman/utils/checkpoint.py:39: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/azhir/Dora/pytorch_lightning')\n",
    "from craftsman.models.autoencoders.michelangelo_autoencoder import MichelangeloAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03edeb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained shape model from /home/azhir/Dora/pytorch_lightning/ckpts/Dora-VAE-1.1/dora_vae_1_1.ckpt\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL omegaconf.listconfig.ListConfig was not an allowed global by default. Please use `torch.serialization.add_safe_globals([omegaconf.listconfig.ListConfig])` or the `torch.serialization.safe_globals([omegaconf.listconfig.ListConfig])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m config_dict \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Instantiate the model with the dictionary\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMichelangeloAutoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set the model to evaluation mode\u001b[39;00m\n",
      "File \u001b[0;32m~/Dora/pytorch_lightning/craftsman/utils/base.py:102\u001b[0m, in \u001b[0;36mBaseModule.__init__\u001b[0;34m(self, cfg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg \u001b[38;5;241m=\u001b[39m parse_structured(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mConfig, cfg)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m get_device()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# format: path/to/weights:module_name\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     weights_path, module_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mweights\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Dora/pytorch_lightning/craftsman/models/autoencoders/michelangelo_autoencoder.py:307\u001b[0m, in \u001b[0;36mMichelangeloAutoencoder.configure\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mpretrained_model_name_or_path \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading pretrained shape model from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 307\u001b[0m     pretrained_ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m pretrained_ckpt:\n\u001b[1;32m    309\u001b[0m         _pretrained_ckpt \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniconda3/envs/dora_env/lib/python3.10/site-packages/torch/serialization.py:1524\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1516\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[1;32m   1517\u001b[0m                     opened_zipfile,\n\u001b[1;32m   1518\u001b[0m                     map_location,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1521\u001b[0m                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[1;32m   1522\u001b[0m                 )\n\u001b[1;32m   1523\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1524\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[1;32m   1526\u001b[0m             opened_zipfile,\n\u001b[1;32m   1527\u001b[0m             map_location,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[1;32m   1531\u001b[0m         )\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL omegaconf.listconfig.ListConfig was not an allowed global by default. Please use `torch.serialization.add_safe_globals([omegaconf.listconfig.ListConfig])` or the `torch.serialization.safe_globals([omegaconf.listconfig.ListConfig])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "# Define the configuration\n",
    "config = MichelangeloAutoencoder.Config(\n",
    "    pretrained_model_name_or_path='/home/azhir/Dora/pytorch_lightning/ckpts/Dora-VAE-1.1/dora_vae_1_1.ckpt',\n",
    "    use_downsample=True,\n",
    "    num_latents=256,\n",
    "    point_feats=3,\n",
    "    embed_point_feats=False,\n",
    "    out_dim=1,\n",
    "    embed_dim=64,\n",
    "    embed_type='fourier',\n",
    "    num_freqs=8,\n",
    "    include_pi=False,\n",
    "    width=768,\n",
    "    heads=12,\n",
    "    num_encoder_layers=8,\n",
    "    num_decoder_layers=16,\n",
    "    init_scale=0.25,\n",
    "    qkv_bias=False,\n",
    "    use_ln_post=True,\n",
    "    use_flash=True,\n",
    "    use_checkpoint=True\n",
    ")\n",
    "\n",
    "# Convert Config object to dictionary\n",
    "config_dict = config.__dict__\n",
    "\n",
    "# Instantiate the model with the dictionary\n",
    "model = MichelangeloAutoencoder(cfg=config_dict)\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedd6a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Output: tensor([[[-0.3500,  0.9348,  0.7684,  ..., -0.4283, -0.0028, -0.3117],\n",
      "         [-0.3990,  0.8272,  0.3626,  ..., -0.3487, -0.2049,  0.4440],\n",
      "         [ 0.5666,  0.6042, -0.7087,  ..., -0.2170, -0.1330,  0.1176],\n",
      "         ...,\n",
      "         [-0.2403,  0.9295, -0.6673,  ..., -0.5174, -0.3436,  0.4496],\n",
      "         [ 0.2973, -0.1050,  1.8477,  ..., -0.0144, -0.3656,  1.3114],\n",
      "         [-0.9137,  0.2099,  2.6271,  ...,  0.0644,  0.2043,  0.8217]]],\n",
      "       grad_fn=<CheckpointFunctionBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Generate random latent codes\n",
    "import torch\n",
    "latent_code = torch.randn(1, 256, 64)  # [Batch, num_latents, embed_dim]\n",
    "\n",
    "# Decode the latent codes into shapes\n",
    "decoded_output = model.decode(latent_code)\n",
    "\n",
    "# Print the decoded outpu\n",
    "print('Decoded Output:', decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038c2132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_output.shape\n",
    "\n",
    "git remote set-url origin git@github.com:azhir-physicsx/DORA_VAE.git\n",
    "\n",
    "git@github.com:azhir-physicsx/DORA_VAE.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c74cb8",
   "metadata": {},
   "source": [
    "# Updates Made\n",
    "- Fixed a syntax error in `shape_autoencoder.py` related to string formatting in the `get_save_path` method.\n",
    "- Updated deprecated usage of `torch.cuda.amp.custom_bwd` to `torch.amp.custom_bwd` with `device_type='cuda'` in `checkpoint.py`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dora_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
